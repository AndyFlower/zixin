## 什么是爬虫
- 形象概念： 爬虫，即网络爬虫，大家可以理解为在网络上爬行的一直蜘蛛，互联网就比作一张大网，而爬虫便是在这张网上爬来爬去的蜘蛛咯，如果它遇到资源，那么它就会抓取下来。想抓取什么？这个由你来控制它。

- 学术概念：爬虫就是通过编写程序模拟浏览器上网，让其去互联网上抓取数据的过程。

## 爬虫的价值

抓取互联网上的数据，为我所用，有了大量的数据，就如同有了一个数据银行一样，下一步做的就是如何将这些爬取的数据产品化，商业化。

## 爬虫究竟是合法还是违法的？

爬虫是用来批量获得网页上的公开信息的，也就是前端显示的数据信息。因此，既然本身就是公开信息，其实就像浏览器一样，浏览器解析并显示了页面内容，爬虫也是一样，只不过爬虫会批量下载而已，所以是合法的。不合法的情况就是配合爬虫，利用黑客技术攻击网站后台，窃取后台数据（比如用户数据等）

## 爬虫所带来风险主要体现在以下2个方面：


- 爬虫干扰了被访问网站的正常运营；

- 爬虫抓取了受到法律保护的特定类型的数据或信息。

## 那么作为爬虫开发者，如何进行爬虫？

- 严格遵守网站设置的robots协议；

- 在规避反爬虫措施的同时，需要优化自己的代码，避免干扰被访问网站的正常运行；

- 在使用、传播抓取到的信息时，应审查所抓取的内容，如发现属于用户的个人信息、隐私或者他人的商业秘密的，应及时停止并删除。

## 爬虫的分类

- 通用爬虫：通用爬虫是搜索引擎（Baidu、Google、Yahoo等）“抓取系统”的重要组成部分。主要目的是将互联网上的网页下载到本地，形成一个互联网内容的镜像备份。 简单来讲就是尽可能的；把互联网上的所有的网页下载下来，放到本地服务器里形成备分，在对这些网页做相关处理(提取关键字、去掉广告)，最后提供一个用户检索接口。

- 聚焦爬虫：聚焦爬虫是根据指定的需求抓取网络上指定的数据。例如：获取豆瓣上电影的名称和影评，而不是获取整张页面中所有的数据值。

- 增量式爬虫：增量式是用来检测网站数据更新的情况，且可以将网站更新的数据进行爬取（后期会有章节单独对其展开详细的讲解）。

## 爬虫的矛与盾

有一个说法是，互联网上50%的流量都是爬虫创造的。这个说法虽然夸张了点，但也体现出了爬虫的无处不在。爬虫之所以无处不在，是因为爬虫可以为互联网企业带来收益。

对于相关的电商网站来说，很多电商网站是愿意被比价网站或者其他购物信息网站爬取信息的，因为这样能够给他们的商品带来更多流量。但他们不愿意被其他电商网站获取价格信息和商品描述，因为担心其他电商网站恶意比价或进行抄袭。同时他们又经常去爬其他电商网站的数据，希望能够看到别人的价格。

## 反爬机制

门户网站通过制定相应的策略和技术手段，防止爬虫程序进行网站数据的爬取。

## 反反爬策略

爬虫程序通过相应的策略和技术手段，破解门户网站的反爬虫手段，从而爬取到相应的数据。

## robots协议

乎是和爬虫技术诞生的同一时刻，反爬虫技术也诞生了。在90年代开始有搜索引擎网站利用爬虫技术抓取网站时，一些搜索引擎从业者和网站站长通过邮件讨论定下了一项“君子协议”—— robots.txt。即网站有权规定网站中哪些内容可以被爬虫抓取，哪些内容不可以被爬虫抓取。这样既可以保护隐私和敏感信息，又可以被搜索引擎收录、增加流量。

历史上第一桩关于爬虫的官司诞生在2000年，eBay将一家聚合价格信息的比价网站BE告上了法庭，eBay声称自己已经将哪些信息不能抓取写进了robots协议中，但BE违反了这一协议。但BE认为eBay上的内容属于用户集体贡献而不归用户所有，爬虫协议不能用作法律参考。最后经过业内反复讨论和法庭上的几轮唇枪舌战，最终以eBay胜诉告终，也开了用爬虫robots协议作为主要参考的先河。

最后，可以通过网站域名 + /robots.txt的形式访问该网站的协议详情，例如：www.taobao.com/robots.txt


## http&https协议

### what is http协议
- 官方概念：HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写,是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。（虽然童鞋们将这条概念都看烂了，但是也没办法，毕竟这就是HTTP的权威官方的概念解释，要想彻底理解，请客观目移下侧……）

- 白话概念：HTTP协议就是服务器（Server）和客户端（Client）之间进行数据交互（相互传输数据）的一种形式。我们可以将Server和Client进行拟人化，那么该协议就是Server和Client这两兄弟间指定的一种交互沟通方式。

### HTTP工作原理

HTTP协议工作于客户端-服务端架构为上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息。

![img](.\images\snip20190410_8.png)

### 常见的请求头信息

- accept:浏览器通过这个头告诉服务器，它所支持的数据类型
- Accept-Charset: 浏览器通过这个头告诉服务器，它支持哪种字符集
- Accept-Encoding：浏览器通过这个头告诉服务器，支持的压缩格式
- Accept-Language：浏览器通过这个头告诉服务器，它的语言环境
- Host：浏览器通过这个头告诉服务器，想访问哪台主机
- If-Modified-Since: 浏览器通过这个头告诉服务器，缓存数据的时间
- Referer：浏览器通过这个头告诉服务器，客户机是哪个页面来的 防盗链
- Connection：浏览器通过这个头告诉服务器，请求完后是断开链接还是何持链接
- X-Requested-With: XMLHttpRequest 代表通过ajax方式进行访问
- User-Agent：请求载体的身份标识

### 常见的响应头信息

-  Location: 服务器通过这个头，来告诉浏览器跳到哪里
-　Server：服务器通过这个头，告诉浏览器服务器的型号
-　Content-Encoding：服务器通过这个头，告诉浏览器，数据的压缩格式
-　Content-Length: 服务器通过这个头，告诉浏览器回送数据的长度
-　Content-Language: 服务器通过这个头，告诉浏览器语言环境
-　Content-Type：服务器通过这个头，告诉浏览器回送数据的类型
-　Refresh：服务器通过这个头，告诉浏览器定时刷新
-　Content-Disposition: 服务器通过这个头，告诉浏览器以下载方式打数据
-　Transfer-Encoding：服务器通过这个头，告诉浏览器数据是以分块方式回送的
-　Expires: -1 控制浏览器不要缓存
-　Cache-Control: no-cache 
-　Pragma: no-cache

### https协议

HTTPS (Secure Hypertext Transfer Protocol)安全超文本传输协议，HTTPS是在HTTP上建立SSL加密层，并对传输数据进行加密，是HTTP协议的安全版。

![img](.\images\snip20190410_3.png)

### https加密算法

- 对称秘钥加密：客户端向服务器发送一条信息，首先客户端会采用已知的算法对信息进行加密，比如MD5或者Base64加密，接收端对加密的信息进行解密的时候需要用到密钥，中间会传递密钥，（加密和解密的密钥是同一个），密钥在传输中间是被加密的。这种方式看起来安全，但是仍有潜在的危险，一旦被窃听，或者信息被挟持，就有可能破解密钥，而破解其中的信息。因此“共享密钥加密”这种方式存在安全隐患。

  ![img](.\images\snip20190410_5.png)

- 非对称秘钥加密：“非对称加密”使用的时候有两把锁，一把叫做“私有密钥”，一把是“公开密钥”，使用非对象加密的加密方式的时候，服务器首先告诉客户端按照自己给定的公开密钥进行加密处理，客户端按照公开密钥加密以后，服务器接受到信息再通过自己的私有密钥进行解密，这样做的好处就是解密的钥匙根本就不会进行传输，因此也就避免了被挟持的风险。就算公开密钥被窃听者拿到了，它也很难进行解密，因为解密过程是对离散对数求值，这可不是轻而易举就能做到的事。以下是非对称加密的原理图：

  ![img](.\images\snip20190410_6.png)

- 但是非对称秘钥加密技术也存在如下缺点：

  - 第一个是：如何保证接收端向发送端发出公开秘钥的时候，发送端确保收到的是预先要发送的，而不会被挟持。只要是发送密钥，就有可能有被挟持的风险。
  - 第二个是：非对称加密的方式效率比较低，它处理起来更为复杂，通信过程中使用就有一定的效率问题而影响通信速度

- **证书秘钥加密：**在上面我们讲了非对称加密的缺点，其中第一个就是公钥很可能存在被挟持的情况，无法保证客户端收到的公开密钥就是服务器发行的公开密钥。此时就引出了公开密钥证书机制。数字证书认证机构是客户端与服务器都可信赖的第三方机构。证书的具体传播过程如下：

  - 服务器的开发者携带公开密钥，向数字证书认证机构提出公开密钥的申请，数字证书认证机构在认清申请者的身份，审核通过以后，会对开发者申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将密钥放在证书里面，绑定在一起

  - 服务器将这份数字证书发送给客户端，因为客户端也认可证书机构，客户端可以通过数字证书中的数字签名来验证公钥的真伪，来确保服务器传过来的公开密钥是真实的。一般情况下，证书的数字签名是很难被伪造的，这取决于认证机构的公信力。一旦确认信息无误之后，客户端就会通过公钥对报文进行加密发送，服务器接收到以后用自己的私钥进行解密。

    ![img](.\images\snip20190410_7.png)

